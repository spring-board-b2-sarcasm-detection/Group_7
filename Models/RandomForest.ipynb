{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615ed86d-f466-4c5d-ad95-30056307baf2",
   "metadata": {},
   "source": [
    "Summary of the Entire Code in 5 Steps\n",
    "Data Loading and Preprocessing:\n",
    "\n",
    "Load the dataset: The dataset is loaded from a CSV file using the pandas library, which reads the data into a DataFrame.\n",
    "Drop null values: Rows with null values in the 'comment' column are removed to ensure that the data is clean and ready for processing.\n",
    "Data Splitting:\n",
    "\n",
    "Separate features and target: The comments are extracted as features (X), and the corresponding labels are extracted as the target (y).\n",
    "Train-test split: The data is split into training and testing sets using an 80-20 ratio. This means 80% of the data is used to train the model, and 20% is used to evaluate its performance. The split is done in a way that ensures reproducibility by setting a random state.\n",
    "Text Vectorization:\n",
    "\n",
    "TF-IDF Vectorization: The text data (comments) is converted into numerical vectors using the TF-IDF (Term Frequency-Inverse Document Frequency) method. This process transforms the text into a format that the machine learning model can understand by representing each comment as a vector of numbers that reflect the importance of each word in the corpus.\n",
    "Model Training:\n",
    "\n",
    "Initialize the Random Forest model: A Random Forest classifier is created with 100 trees. Random Forest is an ensemble learning method that builds multiple decision trees and merges them to get a more accurate and stable prediction.\n",
    "Train the model: The Random Forest model is trained on the TF-IDF vectorized training data. The model learns to map the input text vectors to the corresponding labels.\n",
    "Model Evaluation and Visualization:\n",
    "\n",
    "Make predictions: The trained model is used to make predictions on the test data.\n",
    "Calculate accuracy: The accuracy of the model is calculated, which measures the proportion of correctly predicted instances out of the total instances.\n",
    "Print classification report: A detailed classification report is printed, which includes metrics such as precision, recall, F1-score, and support for each class.\n",
    "Compute confusion matrix: The confusion matrix is computed to provide a detailed breakdown of the model's performance, showing the counts of true positive, true negative, false positive, and false negative predictions.\n",
    "Visualize confusion matrix: The confusion matrix is visualized using a heatmap, which provides an intuitive understanding of the model's performance in distinguishing between the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91267e-361e-43d6-b99c-2951bf3e7105",
   "metadata": {},
   "source": [
    " Random Forest Model \n",
    "Improved Accuracy and Robustness:\n",
    "\n",
    "Random Forest combines the predictions of multiple decision trees, leading to improved accuracy and robustness. By averaging the results of many trees, it reduces the risk of overfitting and produces more reliable predictions.\n",
    "Handling of High-Dimensional Data:\n",
    "\n",
    "Random Forest is capable of handling high-dimensional data and can model complex interactions between features. It is well-suited for datasets with a large number of features, making it a versatile choice for various applications.\n",
    "Feature Importance:\n",
    "\n",
    "Random Forest provides insights into feature importance, helping to identify which features are most influential in making predictions. This is valuable for understanding the underlying patterns in the data and for feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2dd3ec-d835-402f-838d-42697b6560e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "Null values dropped from the dataset.\n",
      "Data split into training and testing sets.\n",
      "Text data vectorized using TF-IDF.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'cleaned_balanced_dataset_FINAL.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Dataset loaded successfully.\")  # Added print statement\n",
    "\n",
    "# Drop rows with null values in the 'comment' column\n",
    "data = data.dropna(subset=['comment'])\n",
    "print(\"Null values dropped from the dataset.\")  # Added print statement\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = data['comment']\n",
    "y = data['label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Data split into training and testing sets.\")  # Added print statement\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(\"Text data vectorized using TF-IDF.\")  # Added print statement\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "print(\"Model trained successfully.\")  # Added print statement\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"Predictions made on the test set.\")  # Added print statement\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')  # Added print statement\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))  # Added print statement\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualize the Confusion Matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
