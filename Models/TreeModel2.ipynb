{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05db2ad4-6779-423b-a62a-3b5663f5c00c",
   "metadata": {},
   "source": [
    "\n",
    "Summary\n",
    "Cell 1: Ensures all necessary libraries are imported and the dataset is loaded successfully. It prints the first few rows of the dataset to confirm loading.\n",
    "Cell 2: Preprocesses the data, handles missing values, vectorizes text data, and splits the dataset into training and testing sets. It prints shapes of the training and testing data to confirm preprocessing.\n",
    "Cell 3: Performs hyperparameter tuning using GridSearchCV. It prints a message when GridSearchCV starts and ends, and outputs the best parameters found.\n",
    "Cell 4: Trains the decision tree model using the best hyperparameters and confirms training completion with a print statement.\n",
    "Cell 5: Makes predictions and assesses accuracy. It prints the accuracy score, detailed classification report, and confusion matrix.\n",
    "Cell 6: Visualizes the decision tree and prints the tree rules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bcfff4-a630-479d-af5a-41ab46fd210d",
   "metadata": {},
   "source": [
    " Decision Tree Model \n",
    "Interpretability:\n",
    "\n",
    "Decision trees are straightforward to interpret. The visual representation of the tree structure makes it easy to understand how decisions are made, which features are used at each split, and how the final prediction is derived.\n",
    "Handling of Non-Linear Relationships:\n",
    "\n",
    "Decision trees can capture and model non-linear relationships between features and the target variable. This makes them suitable for complex datasets where the relationship between input variables and the output is not linear.\n",
    "Feature Selection:\n",
    "\n",
    "Decision trees perform implicit feature selection by choosing the most informative features to split on at each node. This helps in reducing the dimensionality of the data and focusing on the most relevant features for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add3baaf-7d08-4f7a-9e5f-89935ccae7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Here are the first few rows:\n",
      "   label                                            comment\n",
      "0      1                                               need\n",
      "1      0                               might well milk last\n",
      "2      1                                       ask locktrap\n",
      "3      1  im glad community doesnt make console player f...\n",
      "4      0                                    joke put stitch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import export_text, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'cleaned_balanced_dataset_FINAL.csv'  # Ensure this is the correct path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(\"Data loaded successfully. Here are the first few rows:\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61af7d13-017b-47f2-a26e-2a40a6241d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed successfully. Shape of training data: (91021, 53030)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'label' is the target variable and the rest are features\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "# Handle missing values in the 'comment' column\n",
    "X['comment'].fillna('', inplace=True)\n",
    "\n",
    "# If the features are text, vectorize them\n",
    "vectorizer = CountVectorizer()\n",
    "X_vect = vectorizer.fit_transform(X['comment'])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Data preprocessed successfully. Shape of training data:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d11c5-a3d6-4ec3-88c5-40ad284c590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Parameters: {best_params}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0d47a-9fb4-460c-a0c4-60b50bb56ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the best parameters\n",
    "clf_best = DecisionTreeClassifier(**best_params, random_state=42)\n",
    "clf_best.fit(X_train, y_train)\n",
    "print(\"Model trained successfully with best parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ee4449-e98c-459c-be27-7f02e7315b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = clf_best.predict(X_test)\n",
    "\n",
    "# Assess the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Detailed classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7903162-3188-4ed1-abc8-9f52637cc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Decision Tree\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf_best, filled=True, feature_names=vectorizer.get_feature_names_out(), class_names=['0', '1'], rounded=True)\n",
    "plt.show()\n",
    "\n",
    "# Display the tree as text\n",
    "tree_rules = export_text(clf_best, feature_names=list(vectorizer.get_feature_names_out()))\n",
    "print(\"Decision Tree Rules:\")\n",
    "print(tree_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea246b50-9931-4b69-b916-8c3c5e3f71c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
