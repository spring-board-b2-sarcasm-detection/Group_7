{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3614054b-e407-4ba2-966b-f3e6d1af3351",
   "metadata": {},
   "source": [
    "Models Used:\n",
    "Multi-Layer Perceptron (MLP)\n",
    "Convolutional Neural Network (CNN)\n",
    "Long Short-Term Memory (LSTM)\n",
    "Recurrent Neural Network (RNN)\n",
    "Steps:\n",
    "Data Loading and Preprocessing:\n",
    "\n",
    "Load the dataset.\n",
    "Handle missing values in the 'comment' column by filling them with an empty string.\n",
    "Encode the target labels using LabelEncoder.\n",
    "Vectorize the text data using TF-IDF with a maximum of 5000 features.\n",
    "Split the data into training and testing sets.\n",
    "Standardize the features.\n",
    "Model Building:\n",
    "\n",
    "Define a function to build and compile models based on the specified type (MLP, CNN, LSTM, RNN).\n",
    "Add appropriate layers for each model type, with specific configurations for each (e.g., Dense layers for MLP, Conv1D for CNN).\n",
    "Model Training and Evaluation:\n",
    "\n",
    "Train each model on the training data for 10 epochs with a batch size of 32.\n",
    "Predict the test data and compute the F1 scores.\n",
    "Print and compare the F1 scores for each model.\n",
    "Comparison:\n",
    "Models are compared based on their F1 scores, which measure the balance between precision and recall.\n",
    "The performance of each model is evaluated to determine which one handles the classification task most effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355a121c-bc46-436e-8ae6-8e8c60b7ff95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\anaconda4\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Shubham\\anaconda4\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\Shubham\\anaconda4\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP model...\n",
      "Epoch 1/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step - accuracy: 0.5985 - loss: 0.6741\n",
      "Epoch 2/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.6922 - loss: 0.5813\n",
      "Epoch 3/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.7302 - loss: 0.5340\n",
      "Epoch 4/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.7739 - loss: 0.4731\n",
      "Epoch 5/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8187 - loss: 0.3980\n",
      "Epoch 6/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8550 - loss: 0.3311\n",
      "Epoch 7/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8794 - loss: 0.2821\n",
      "Epoch 8/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.8956 - loss: 0.2491\n",
      "Epoch 9/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9043 - loss: 0.2235\n",
      "Epoch 10/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9125 - loss: 0.2063\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
      "MLP F1 Score: 0.6126870324189526\n",
      "Training CNN model...\n",
      "Epoch 1/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 17ms/step - accuracy: 0.6088 - loss: 0.6781\n",
      "Epoch 2/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 16ms/step - accuracy: 0.6696 - loss: 0.6059\n",
      "Epoch 3/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 17ms/step - accuracy: 0.6779 - loss: 0.5942\n",
      "Epoch 4/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 17ms/step - accuracy: 0.6827 - loss: 0.5908\n",
      "Epoch 5/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 17ms/step - accuracy: 0.6843 - loss: 0.5876\n",
      "Epoch 6/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 17ms/step - accuracy: 0.6868 - loss: 0.5860\n",
      "Epoch 7/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 17ms/step - accuracy: 0.6868 - loss: 0.5833\n",
      "Epoch 8/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 17ms/step - accuracy: 0.6893 - loss: 0.5824\n",
      "Epoch 9/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 17ms/step - accuracy: 0.6889 - loss: 0.5820\n",
      "Epoch 10/10\n",
      "\u001b[1m3251/3251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 17ms/step - accuracy: 0.6920 - loss: 0.5799\n",
      "\u001b[1m813/813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step\n",
      "CNN F1 Score: 0.6355432559258815\n",
      "Training LSTM model...\n",
      "Epoch 1/10\n",
      "\u001b[1m 324/3251\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:16:03\u001b[0m 4s/step - accuracy: 0.4977 - loss: 0.6936"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, LSTM, SimpleRNN\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('cleaned_balanced_dataset_FINAL.csv')\n",
    "\n",
    "# Handle missing values in the 'comment' column\n",
    "data['comment'].fillna('', inplace=True)\n",
    "\n",
    "# Encode target labels if necessary\n",
    "label_column = 'label'\n",
    "label_encoder = LabelEncoder()\n",
    "data[label_column] = label_encoder.fit_transform(data[label_column])\n",
    "\n",
    "# Text Vectorization using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(data['comment']).toarray()\n",
    "\n",
    "# Split data into features and target\n",
    "y = data[label_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define a function to build and compile the model\n",
    "def build_and_compile_model(model_type, input_shape):\n",
    "    model = Sequential()\n",
    "    if model_type == 'MLP':\n",
    "        model.add(Dense(64, activation='relu', input_shape=input_shape))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "    elif model_type == 'CNN':\n",
    "        model.add(Conv1D(32, 3, activation='relu', input_shape=input_shape))\n",
    "        model.add(Flatten())\n",
    "    elif model_type == 'LSTM':\n",
    "        model.add(LSTM(64, input_shape=input_shape))\n",
    "    elif model_type == 'RNN':\n",
    "        model.add(SimpleRNN(64, input_shape=input_shape))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshape data for LSTM/RNN models if necessary\n",
    "X_train_rnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test_rnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# Define input shapes for different models\n",
    "input_shape_mlp = (X_train.shape[1],)\n",
    "input_shape_cnn = (X_train.shape[1], 1)\n",
    "input_shape_rnn = (X_train_rnn.shape[1], X_train_rnn.shape[2])\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'MLP': build_and_compile_model('MLP', input_shape_mlp),\n",
    "    'CNN': build_and_compile_model('CNN', input_shape_cnn),\n",
    "    'LSTM': build_and_compile_model('LSTM', input_shape_rnn),\n",
    "    'RNN': build_and_compile_model('RNN', input_shape_rnn)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "f1_scores = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name} model...\")\n",
    "    if model_name == 'CNN':\n",
    "        model.fit(X_train.reshape(X_train.shape[0], X_train.shape[1], 1), y_train, epochs=10, batch_size=32, verbose=1)\n",
    "        y_pred = (model.predict(X_test.reshape(X_test.shape[0], X_test.shape[1], 1)) > 0.5).astype(\"int32\")\n",
    "    elif model_name in ['LSTM', 'RNN']:\n",
    "        model.fit(X_train_rnn, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "        y_pred = (model.predict(X_test_rnn) > 0.5).astype(\"int32\")\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "        y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1_scores[model_name] = f1\n",
    "    print(f\"{model_name} F1 Score: {f1}\")\n",
    "\n",
    "# Display F1 scores\n",
    "print(\"F1 Scores for different models:\")\n",
    "for model_name, score in f1_scores.items():\n",
    "    print(f\"{model_name}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045cbb19-cfd8-4eeb-9ccc-d414fc336c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
