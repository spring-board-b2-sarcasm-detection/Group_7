{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ec8ef1-ed89-4351-a545-e8e0d5cb2899",
   "metadata": {},
   "source": [
    "Models Used:\n",
    "Multi-Layer Perceptron (MLP)\n",
    "Convolutional Neural Network (CNN)\n",
    "Long Short-Term Memory (LSTM)\n",
    "Recurrent Neural Network (RNN)\n",
    "Steps:\n",
    "Data Loading and Preprocessing:\n",
    "\n",
    "Load the dataset.\n",
    "Handle missing values in the 'comment' column by filling them with an empty string.\n",
    "Encode the target labels using LabelEncoder.\n",
    "Vectorize the text data using TF-IDF with a maximum of 5000 features.\n",
    "Split the data into training and testing sets.\n",
    "Standardize the features.\n",
    "Model Building:\n",
    "\n",
    "Define a function to build and compile models based on the specified type (MLP, CNN, LSTM, RNN).\n",
    "Add appropriate layers for each model type, with specific configurations for each (e.g., Dense layers for MLP, Conv1D for CNN).\n",
    "Model Training and Evaluation:\n",
    "\n",
    "Train each model on the training data for 10 epochs with a batch size of 32.\n",
    "Predict the test data and compute the accuracy scores.\n",
    "Print and compare the accuracy scores for each model.\n",
    "Comparison:\n",
    "Models are compared based on their accuracy scores, which measure the proportion of correctly classified instances out of the total instances.\n",
    "The performance of each model is evaluated to determine which one achieves the highest classification accuracy.\n",
    "Key Differences:\n",
    "\n",
    "\n",
    "F1 Score: Focuses on the balance between precision and recall, making it suitable for imbalanced datasets.\n",
    "Accuracy: Measures the overall correctness of the model, making it suitable for balanced datasets where both false positives and false negatives are equally important.\n",
    "Both metrics provide valuable insights into model performance, and choosing between them depends on the specific requirements and characteristics of the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76af84ef-3cfd-4030-b7c1-5c9044628953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\shubham\\anaconda4\\lib\\site-packages (1.4.7)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: keras in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras->keras-tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras->keras-tuner) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras->keras-tuner) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras->keras-tuner) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from keras->keras-tuner) (0.3.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from requests->keras-tuner) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from requests->keras-tuner) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from optree->keras->keras-tuner) (4.9.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from rich->keras->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from rich->keras->keras-tuner) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shubham\\anaconda4\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras->keras-tuner) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf5c35-f658-4663-a39b-2ac9a01a843f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 00m 51s]\n",
      "\n",
      "Best val_accuracy So Far: 0.6554674506187439\n",
      "Total elapsed time: 00h 19m 22s\n",
      "\n",
      "Search: Running Trial #10\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "CNN               |CNN               |model_type\n",
      "192               |32                |units_mlp\n",
      "64                |384               |units_mlp2\n",
      "64                |224               |units_rnn\n",
      "32                |128               |filters\n",
      "3                 |5                 |kernel_size\n",
      "2                 |2                 |tuner/epochs\n",
      "0                 |0                 |tuner/initial_epoch\n",
      "2                 |2                 |tuner/bracket\n",
      "0                 |0                 |tuner/round\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Conv1D, Flatten, LSTM, SimpleRNN\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('cleaned_balanced_dataset_FINAL.csv')\n",
    "\n",
    "# Handle missing values in the 'comment' column\n",
    "data['comment'].fillna('', inplace=True)\n",
    "\n",
    "# Encode target labels if necessary\n",
    "label_column = 'label'\n",
    "label_encoder = LabelEncoder()\n",
    "data[label_column] = label_encoder.fit_transform(data[label_column])\n",
    "\n",
    "# Text Vectorization using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(data['comment']).toarray()\n",
    "\n",
    "# Split data into features and target\n",
    "y = data[label_column]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the hypermodel\n",
    "def build_hypermodel(hp):\n",
    "    model = Sequential()\n",
    "    model_type = hp.Choice('model_type', ['MLP', 'CNN', 'LSTM', 'RNN'])\n",
    "    if model_type == 'CNN':\n",
    "        model.add(Input(shape=(X_train.shape[1], 1)))\n",
    "        model.add(Conv1D(filters=hp.Int('filters', min_value=32, max_value=128, step=32), kernel_size=hp.Choice('kernel_size', [3, 5, 7]), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "    else:\n",
    "        model.add(Input(shape=(X_train.shape[1],)))\n",
    "        if model_type == 'MLP':\n",
    "            model.add(Dense(units=hp.Int('units_mlp', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "            model.add(Dense(units=hp.Int('units_mlp2', min_value=32, max_value=512, step=32), activation='relu'))\n",
    "        elif model_type == 'LSTM':\n",
    "            model.add(LSTM(units=hp.Int('units_lstm', min_value=32, max_value=256, step=32)))\n",
    "        elif model_type == 'RNN':\n",
    "            model.add(SimpleRNN(units=hp.Int('units_rnn', min_value=32, max_value=256, step=32)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reshape data for CNN\n",
    "X_train_cnn = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_cnn = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_hypermodel,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='hyperband',\n",
    "    project_name='text_classification'\n",
    ")\n",
    "\n",
    "# Define a callback to stop training early if the validation loss does not improve\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Run the tuner search\n",
    "tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the best model\n",
    "if best_hps.get('model_type') == 'CNN':\n",
    "    best_model.fit(X_train_cnn, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "else:\n",
    "    best_model.fit(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Evaluate the model\n",
    "if best_hps.get('model_type') == 'CNN':\n",
    "    y_pred = (best_model.predict(X_test_cnn) > 0.5).astype(\"int32\")\n",
    "else:\n",
    "    y_pred = (best_model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best Model Accuracy: {accuracy}\")\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(f\"Best hyperparameters: {best_hps.values}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
