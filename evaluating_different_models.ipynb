{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00f94010-a4d0-4ec2-b58f-fdba6cd54da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('balanced_dataset_50000.csv')\n",
    "\n",
    "# Drop rows with NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "# Preprocess the dataset\n",
    "X = data['comment']\n",
    "y = data['label']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to strings to handle potential float values\n",
    "X_train = X_train.astype(str)\n",
    "X_test = X_test.astype(str)\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "max_words = 10000  # Maximum number of words to keep based on frequency\n",
    "maxlen = 100  # Maximum length of sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac038fe-d573-44aa-8fb9-8958cda4078f",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b03688-f53e-4632-814f-6b73a02aa87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 193ms/step - accuracy: 0.5711 - loss: 0.6715 - val_accuracy: 0.6697 - val_loss: 0.6075\n",
      "Epoch 2/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 189ms/step - accuracy: 0.7132 - loss: 0.5554 - val_accuracy: 0.6515 - val_loss: 0.6206\n",
      "Epoch 3/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 188ms/step - accuracy: 0.7707 - loss: 0.4778 - val_accuracy: 0.6439 - val_loss: 0.6652\n",
      "Epoch 4/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 192ms/step - accuracy: 0.8016 - loss: 0.4198 - val_accuracy: 0.6323 - val_loss: 0.7301\n",
      "Epoch 5/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 186ms/step - accuracy: 0.8299 - loss: 0.3647 - val_accuracy: 0.6258 - val_loss: 0.8527\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 48ms/step\n",
      "LSTM Model\n",
      "Accuracy: 0.6298989898989898\n",
      "Precision: 0.6400583576490204\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63      4892\n",
      "           1       0.64      0.61      0.63      5008\n",
      "\n",
      "    accuracy                           0.63      9900\n",
      "   macro avg       0.63      0.63      0.63      9900\n",
      "weighted avg       0.63      0.63      0.63      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128),\n",
    "    LSTM(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lstm_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lstm = (lstm_model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "print('LSTM Model')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_lstm))\n",
    "print('Precision:', precision_score(y_test, y_pred_lstm))\n",
    "print('Classification Report:', classification_report(y_test, y_pred_lstm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04892fba-6a15-43c2-8450-22062020a2c3",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401e1463-0eff-482e-8cb3-d7c8d2246da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model\n",
      "Accuracy: 0.5583838383838384\n",
      "Precision: 0.5615801704105344\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55      4892\n",
      "           1       0.56      0.58      0.57      5008\n",
      "\n",
      "    accuracy                           0.56      9900\n",
      "   macro avg       0.56      0.56      0.56      9900\n",
      "weighted avg       0.56      0.56      0.56      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest Model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_pad, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_rf = rf_model.predict(X_test_pad)\n",
    "print('Random Forest Model')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print('Precision:', precision_score(y_test, y_pred_rf))\n",
    "print('Classification Report:', classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f9e64-94f0-4709-b503-9b896b94bfcf",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e91c1908-1b7a-4c67-9903-92214c808eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haree\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.4977 - loss: 43.1391 - val_accuracy: 0.4932 - val_loss: 0.6977\n",
      "Epoch 2/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.5023 - loss: 0.8707 - val_accuracy: 0.4899 - val_loss: 0.6942\n",
      "Epoch 3/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4997 - loss: 0.7362 - val_accuracy: 0.4899 - val_loss: 0.6978\n",
      "Epoch 4/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5078 - loss: 0.7166 - val_accuracy: 0.4909 - val_loss: 0.6932\n",
      "Epoch 5/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5044 - loss: 0.7064 - val_accuracy: 0.4904 - val_loss: 0.6934\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Neural Network Model\n",
      "Accuracy: 0.5059595959595959\n",
      "Precision: 0.5059096878472573\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00      4892\n",
      "           1       0.51      1.00      0.67      5008\n",
      "\n",
      "    accuracy                           0.51      9900\n",
      "   macro avg       0.75      0.50      0.34      9900\n",
      "weighted avg       0.75      0.51      0.34      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Model\n",
    "nn_model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(maxlen,)),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "nn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "nn_model.fit(X_train_pad, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_nn = (nn_model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "print('Neural Network Model')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_nn))\n",
    "print('Precision:', precision_score(y_test, y_pred_nn))\n",
    "print('Classification Report:', classification_report(y_test, y_pred_nn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a89b66-8d7f-4a21-91e2-25dc9b885e38",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b98203-aaf4-40c2-9f7c-f974d07f3896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 1, 'kernel': 'rbf'}\n",
      "Best CV Accuracy: 64.94%\n",
      "\n",
      "SVM Model with Tuning and Epochs (Cross-Validation Folds)\n",
      "Training Accuracy: 88.35%\n",
      "Training Precision: 90.35%\n",
      "Test Accuracy: 65.22%\n",
      "Test Precision: 67.61%\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.67      4892\n",
      "           1       0.68      0.60      0.64      5008\n",
      "\n",
      "    accuracy                           0.65      9900\n",
      "   macro avg       0.65      0.65      0.65      9900\n",
      "weighted avg       0.65      0.65      0.65      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#IMPROVED\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# SVM Model with GridSearchCV for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf']  # Kernel type\n",
    "}\n",
    "\n",
    "# Number of cross-validation folds (epochs)\n",
    "num_epochs = 5\n",
    "\n",
    "svm_model = GridSearchCV(SVC(random_state=42), param_grid, cv=num_epochs, scoring='accuracy')\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Best parameters and best score from grid search\n",
    "print(\"Best Parameters: \", svm_model.best_params_)\n",
    "print(\"Best CV Accuracy: {:.2f}%\".format(svm_model.best_score_ * 100))\n",
    "\n",
    "# Training accuracy and precision\n",
    "train_predictions_svm = svm_model.predict(X_train_tfidf)\n",
    "train_accuracy_svm = accuracy_score(y_train, train_predictions_svm)\n",
    "train_precision_svm = precision_score(y_train, train_predictions_svm)\n",
    "\n",
    "# Test accuracy and precision\n",
    "test_predictions_svm = svm_model.predict(X_test_tfidf)\n",
    "test_accuracy_svm = accuracy_score(y_test, test_predictions_svm)\n",
    "test_precision_svm = precision_score(y_test, test_predictions_svm)\n",
    "\n",
    "# Print results\n",
    "print('\\nSVM Model with Tuning and Epochs (Cross-Validation Folds)')\n",
    "print(f'Training Accuracy: {train_accuracy_svm * 100:.2f}%')\n",
    "print(f'Training Precision: {train_precision_svm * 100:.2f}%')\n",
    "print(f'Test Accuracy: {test_accuracy_svm * 100:.2f}%')\n",
    "print(f'Test Precision: {test_precision_svm * 100:.2f}%')\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, test_predictions_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa16aff-e7a4-48f2-b6b7-ab16e92cf365",
   "metadata": {},
   "source": [
    "# GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a184aa1-096c-4d7c-8d3b-b6acafc4c236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 81ms/step - accuracy: 0.5826 - loss: 0.6637 - val_accuracy: 0.6667 - val_loss: 0.6169\n",
      "Epoch 2/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 84ms/step - accuracy: 0.7293 - loss: 0.5406 - val_accuracy: 0.6409 - val_loss: 0.6350\n",
      "Epoch 3/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 81ms/step - accuracy: 0.7682 - loss: 15641.9834 - val_accuracy: 0.6167 - val_loss: 0.6925\n",
      "Epoch 4/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 80ms/step - accuracy: 0.8050 - loss: 0.4241 - val_accuracy: 0.6111 - val_loss: 0.7327\n",
      "Epoch 5/5\n",
      "\u001b[1m557/557\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 80ms/step - accuracy: 0.8289 - loss: 0.3825 - val_accuracy: 0.6068 - val_loss: 0.7798\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "GRU Model\n",
      "Accuracy: 0.6173737373737374\n",
      "Precision: 0.6219024780175859\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      4892\n",
      "           1       0.62      0.62      0.62      5008\n",
      "\n",
      "    accuracy                           0.62      9900\n",
      "   macro avg       0.62      0.62      0.62      9900\n",
      "weighted avg       0.62      0.62      0.62      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "\n",
    "# Assuming you have X_train_pad, X_test_pad, y_train, and y_test ready\n",
    "\n",
    "# Create the GRU model\n",
    "gru_model = Sequential([\n",
    "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128),  # Remove input_length\n",
    "    GRU(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "epochs = 5  # Number of epochs to train\n",
    "batch_size = 64  # Batch size for training\n",
    "validation_split = 0.1  # Fraction of training data to use for validation\n",
    "\n",
    "history = gru_model.fit(X_train_pad, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_gru = (gru_model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "print('GRU Model')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_gru))\n",
    "print('Precision:', precision_score(y_test, y_pred_gru))\n",
    "print('Classification Report:', classification_report(y_test, y_pred_gru))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45410677-096b-4c58-9ccf-6c86903e2834",
   "metadata": {},
   "source": [
    "# Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bde8ee96-fd77-4724-a91d-1b50ed7b0153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model\n",
      "Accuracy: 0.5374747474747474\n",
      "Precision: 0.5440723238134374\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.55      0.54      4892\n",
      "           1       0.54      0.53      0.54      5008\n",
      "\n",
      "    accuracy                           0.54      9900\n",
      "   macro avg       0.54      0.54      0.54      9900\n",
      "weighted avg       0.54      0.54      0.54      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Decision Tree Model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_pad, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_dt = dt_model.predict(X_test_pad)\n",
    "print('Decision Tree Model')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_dt))\n",
    "print('Precision:', precision_score(y_test, y_pred_dt))\n",
    "print('Classification Report:', classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac9856-5728-4da4-b8f7-7582df1e30c9",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d00786-e259-4e42-9036-9a6f52c891a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model\n",
      "Accuracy: 0.565959595959596\n",
      "Precision: 0.5693658536585365\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.55      0.56      4892\n",
      "           1       0.57      0.58      0.58      5008\n",
      "\n",
      "    accuracy                           0.57      9900\n",
      "   macro avg       0.57      0.57      0.57      9900\n",
      "weighted avg       0.57      0.57      0.57      9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train_pad, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_xgb = xgb_model.predict(X_test_pad)\n",
    "print('XGBoost Model')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_xgb))\n",
    "print('Precision:', precision_score(y_test, y_pred_xgb))\n",
    "print('Classification Report:', classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb3d4a-46f3-4e7c-b4e4-9898e64ff852",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef80c59-be6e-4fb5-afd8-71b6ac1e2fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model\n",
      "Accuracy: 0.5194949494949495\n",
      "Precision: 0.5190122708680502\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.35      0.42      4892\n",
      "           1       0.52      0.68      0.59      5008\n",
      "\n",
      "    accuracy                           0.52      9900\n",
      "   macro avg       0.52      0.52      0.50      9900\n",
      "weighted avg       0.52      0.52      0.51      9900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haree\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Logistic Regression Model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_pad, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred_lr = lr_model.predict(X_test_pad)\n",
    "print('Logistic Regression Model')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_lr))\n",
    "print('Precision:', precision_score(y_test, y_pred_lr))\n",
    "print('Classification Report:', classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba81e25-509f-4858-830b-4b1f43f76b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
