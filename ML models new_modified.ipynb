{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3bb74b-79ea-4e69-ae8b-8ab034194aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('balanced_dataset_50000.csv')\n",
    "\n",
    "# Drop rows with NaN values\n",
    "data = data.dropna()\n",
    "\n",
    "# Preprocess the dataset\n",
    "X = data['comment']\n",
    "y = data['label']\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to strings to handle potential float values\n",
    "X_train = X_train.astype(str)\n",
    "X_test = X_test.astype(str)\n",
    "\n",
    "# Tokenize and transform sequences using TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ae0dfa-db74-424e-a3d2-aa99b550c7ac",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ca2c0f-2658-4464-9de9-e85f7ebf2f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6675\n",
      "Test Accuracy: 0.6282\n",
      "Test Precision: 0.6749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Initialize Random Forest model with desired hyperparameters\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "train_accuracy_rf = accuracy_score(y_train, rf_model.predict(X_train_tfidf))\n",
    "test_accuracy_rf = accuracy_score(y_test, rf_model.predict(X_test_tfidf))\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "test_precision_rf = precision_score(y_test, y_pred_rf)\n",
    "\n",
    "rf_results = {\n",
    "    'train_accuracy': train_accuracy_rf,\n",
    "    'test_accuracy': test_accuracy_rf,\n",
    "    'test_precision': test_precision_rf\n",
    "}\n",
    "\n",
    "# Print accuracies\n",
    "print(f\"Training Accuracy: {train_accuracy_rf:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_rf:.4f}\")\n",
    "print(f\"Test Precision: {test_precision_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d7183-148a-488b-a5fb-5abd1b0650e2",
   "metadata": {},
   "source": [
    "#### Parallelization: Ensure that your environment is configured to utilize multiple CPU cores (n_jobs=-1 in RandomForestClassifier) for parallel processing. This can speed up training time significantly, especially on multicore machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb80378-8490-4a1e-9d4c-7267d9a97b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6413\n",
      "Test Accuracy: 0.6140\n",
      "Test Precision: 0.6666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Initialize Random Forest model with reduced parameters\n",
    "rf_model = RandomForestClassifier(n_estimators=50, max_depth=7, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Subset of data for quicker testing\n",
    "# Example: X_train_tfidf_sub, y_train_sub, X_test_tfidf_sub, y_test_sub = train_test_split(X_train_tfidf, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate Random Forest model\n",
    "train_accuracy_rf = accuracy_score(y_train, rf_model.predict(X_train_tfidf))\n",
    "test_accuracy_rf = accuracy_score(y_test, rf_model.predict(X_test_tfidf))\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "test_precision_rf = precision_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print accuracies\n",
    "print(f\"Training Accuracy: {train_accuracy_rf:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_rf:.4f}\")\n",
    "print(f\"Test Precision: {test_precision_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb44306-0a6c-4565-86f3-357f689969e0",
   "metadata": {},
   "source": [
    "# Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19356a5e-8899-4c8f-b8a5-9ddce3986019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.5575\n",
      "Test Accuracy: 0.5506\n",
      "Test Precision: 0.8551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Initialize Decision Tree model with reduced parameters\n",
    "dt_model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "\n",
    "# Train Decision Tree model\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate Decision Tree model\n",
    "train_accuracy_dt = accuracy_score(y_train, dt_model.predict(X_train_tfidf))\n",
    "test_accuracy_dt = accuracy_score(y_test, dt_model.predict(X_test_tfidf))\n",
    "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
    "test_precision_dt = precision_score(y_test, y_pred_dt)\n",
    "\n",
    "dt_results = {\n",
    "    'train_accuracy': train_accuracy_dt,\n",
    "    'test_accuracy': test_accuracy_dt,\n",
    "    'test_precision': test_precision_dt\n",
    "}\n",
    "\n",
    "# Print accuracies\n",
    "print(f\"Training Accuracy: {train_accuracy_dt:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_dt:.4f}\")\n",
    "print(f\"Test Precision: {test_precision_dt:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d59be9c-331e-47ce-85a1-375fed199213",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45fa1ea4-1d9e-4de3-b658-e74e3b4396f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7300\n",
      "Test Accuracy: 0.6458\n",
      "Test Precision: 0.6659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=10)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate Logistic Regression model\n",
    "train_accuracy_lr = accuracy_score(y_train, lr_model.predict(X_train_tfidf))\n",
    "test_accuracy_lr = accuracy_score(y_test, lr_model.predict(X_test_tfidf))\n",
    "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "test_precision_lr = precision_score(y_test, y_pred_lr)\n",
    "\n",
    "# Print accuracies\n",
    "print(f\"Training Accuracy: {train_accuracy_lr:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy_lr:.4f}\")\n",
    "print(f\"Test Precision: {test_precision_lr:.4f}\")\n",
    "\n",
    "# Store results in dictionary\n",
    "lr_results = {\n",
    "    'train_accuracy': train_accuracy_lr,\n",
    "    'test_accuracy': test_accuracy_lr,\n",
    "    'test_precision': test_precision_lr\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce369e72-ae47-4b27-acaa-c6d3b77fb965",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "126525e8-9cf3-4f11-b3b1-911b884e98a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Results:\n",
      "{'train_accuracy': 0.690792464265872, 'test_accuracy': 0.6318181818181818, 'test_precision': 0.7072058376406203}\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Reduce feature dimensionality\n",
    "selector = SelectFromModel(estimator=XGBClassifier(), max_features=1000)\n",
    "X_train_tfidf_selected = selector.fit_transform(X_train_tfidf, y_train)\n",
    "X_test_tfidf_selected = selector.transform(X_test_tfidf)\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = XGBClassifier(tree_method='approx', n_jobs=-1)\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 10\n",
    "\n",
    "# Train and evaluate XGBoost model\n",
    "for epoch in range(epochs):\n",
    "    xgb_model.fit(X_train_tfidf_selected, y_train, verbose=True if epoch == epochs - 1 else False)\n",
    "\n",
    "# Evaluate model performance\n",
    "train_accuracy_xgb = xgb_model.score(X_train_tfidf_selected, y_train)\n",
    "test_accuracy_xgb = xgb_model.score(X_test_tfidf_selected, y_test)\n",
    "y_pred_xgb = xgb_model.predict(X_test_tfidf_selected)\n",
    "test_precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "\n",
    "# Gather results\n",
    "xgb_results = {\n",
    "    'train_accuracy': train_accuracy_xgb,\n",
    "    'test_accuracy': test_accuracy_xgb,\n",
    "    'test_precision': test_precision_xgb\n",
    "}\n",
    "\n",
    "print(\"XGBoost Model Results:\")\n",
    "print(xgb_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc39173-764d-4c51-b7fc-404458794aac",
   "metadata": {},
   "source": [
    "# SVC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf807b88-ed93-40f2-a8ea-25d0dac90dec",
   "metadata": {},
   "source": [
    "When considering whether to use `SVC` (Support Vector Classifier) from `sklearn.svm` for sarcasm detection, here are some key reasons to prefer `SVC` over other approaches within the context of sarcasm detection:\n",
    "\n",
    "### Reasons to Use `SVC`:\n",
    "\n",
    "1. **Effectiveness in High-Dimensional Spaces:**\n",
    "   `SVC` is known for its effectiveness in high-dimensional spaces, which is particularly relevant when dealing with text data that has been transformed into TF-IDF features. The high dimensionality of the feature space can be efficiently handled by the SVC algorithm.\n",
    "\n",
    "2. **Robustness to Overfitting:**\n",
    "   SVMs, including `SVC`, have regularization parameters (`C` in `SVC`) that help prevent overfitting. This is crucial for sarcasm detection, where the model needs to generalize well to new, unseen examples of sarcasm without being too specific to the training data.\n",
    "\n",
    "3. **Kernel Trick:**\n",
    "   `SVC` supports the use of kernel functions, which can map the original features into higher-dimensional spaces where a linear separation is possible. This is beneficial for sarcasm detection, as the relationship between features and labels may not be linearly separable in the original feature space. Using kernels like the RBF (Radial Basis Function) can capture complex patterns in the data.\n",
    "\n",
    "4. **Performance:**\n",
    "   Empirical evidence often shows that `SVC` performs well in text classification tasks, including sarcasm detection. The `SVC` algorithm can achieve high accuracy and precision, making it a strong candidate for this type of task.\n",
    "\n",
    "5. **Scalability:**\n",
    "   While SVMs can be computationally intensive, `SVC` implementations in `scikit-learn` are optimized for performance. They can handle reasonably large datasets efficiently, especially when combined with techniques like grid search for hyperparameter tuning.\n",
    "\n",
    "### Comparison with Other Approaches:\n",
    "\n",
    "- **Logistic Regression:** While logistic regression is simpler and faster, it might not capture the complex patterns in sarcasm detection as effectively as `SVC` with non-linear kernels.\n",
    "- **Decision Trees/Random Forests:** These models can capture non-linear patterns but may require extensive tuning and can be prone to overfitting. They also may not perform as well in high-dimensional spaces compared to `SVC`.\n",
    "- **XGBoost:** While powerful and often performing well in various tasks, XGBoost might be more complex to tune and more computationally intensive compared to `SVC`.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "**SVC** is a strong candidate for sarcasm detection due to its ability to handle high-dimensional feature spaces, robustness against overfitting, support for non-linear classification through kernel functions, and demonstrated empirical performance in text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "120585a7-0d8e-482d-ba80-2ae25fc822a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9129501489974241\n",
      "Test Accuracy: 0.6523232323232323\n",
      "Test Precision: 0.6750111756817165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Initialize SVC model\n",
    "svc_model = SVC()\n",
    "\n",
    "# Fit the model once on the entire training set\n",
    "svc_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate model performance\n",
    "train_accuracy_svc = svc_model.score(X_train_tfidf, y_train)\n",
    "test_accuracy_svc = svc_model.score(X_test_tfidf, y_test)\n",
    "y_pred_svc = svc_model.predict(X_test_tfidf)\n",
    "test_precision_svc = precision_score(y_test, y_pred_svc)\n",
    "\n",
    "svc_results = {\n",
    "    'train_accuracy': train_accuracy_svc,\n",
    "    'test_accuracy': test_accuracy_svc,\n",
    "    'test_precision': test_precision_svc\n",
    "}\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy_svc)\n",
    "print(\"Test Accuracy:\", test_accuracy_svc)\n",
    "print(\"Test Precision:\", test_precision_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d6d5c7-8d64-4905-b857-4cfbf50dbaf3",
   "metadata": {},
   "source": [
    "# Comparison and Best Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5503179-1a21-476e-a9c7-a2a011a184c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model: SVC\n",
      "Training Accuracy: 91.30%\n",
      "Test Accuracy: 65.23%\n",
      "Test Precision: 67.50%\n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "models = {\n",
    "    'Random Forest Model': rf_results,\n",
    "    'Decision Tree Model': dt_results,\n",
    "    'Logistic Regression Model': lr_results,\n",
    "    'XGBoost Model': xgb_results,\n",
    "    'SVC': svc_results\n",
    "}\n",
    "\n",
    "best_model = max(models, key=lambda x: models[x]['test_accuracy'])\n",
    "\n",
    "print(f'\\nBest Model: {best_model}')\n",
    "print(f\"Training Accuracy: {models[best_model]['train_accuracy'] * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {models[best_model]['test_accuracy'] * 100:.2f}%\")\n",
    "print(f\"Test Precision: {models[best_model]['test_precision'] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d0c88-9112-4c5e-90f8-f20129f7ebd2",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b90424-9f79-40eb-8cca-722df26a75bc",
   "metadata": {},
   "source": [
    "### Steps taken\n",
    "1. **Data Loading and Preprocessing:**\n",
    "   The notebook starts by importing essential libraries such as `pandas` and `sklearn`. The dataset (`balanced_dataset_50000.csv`) is loaded and rows with missing values are dropped. The features (`comment`) and labels (`label`) are extracted, and the labels are encoded using `LabelEncoder`. The data is then split into training and testing sets using `train_test_split`.\n",
    "\n",
    "2. **Text Vectorization:**\n",
    "   To prepare the text data for model training, the `TfidfVectorizer` is used to convert the text data into TF-IDF features. This step transforms the text data into a numerical format suitable for machine learning models.\n",
    "\n",
    "3. **Model Training and Evaluation:**\n",
    "   The notebook proceeds to train and evaluate several machine learning models:\n",
    "   - **Random Forest Model:** A Random Forest model is initialized with specific hyperparameters and trained on the TF-IDF features. The model's performance is evaluated based on training accuracy, test accuracy, and precision.\n",
    "   - **Decision Tree Model:** Similarly, a Decision Tree model is initialized, trained, and evaluated.\n",
    "   - **Logistic Regression Model:** A Logistic Regression model undergoes the same process of initialization, training, and evaluation.\n",
    "   - **XGBoost Model:** An XGBoost model is trained and its performance is evaluated in terms of training accuracy, test accuracy, and precision.\n",
    "   - **SVC (Support Vector Classifier) Model:** An SVC model is also trained and evaluated using the same metrics.\n",
    "\n",
    "4. **Model Comparison:**\n",
    "   After training and evaluating all the models, the notebook compares their performance based on test accuracy. The model with the highest test accuracy is identified as the best-performing model.\n",
    "\n",
    "### Conclusion:\n",
    "Among all the models evaluated, the **SVC Model** demonstrated the best performance. The performance metrics for the SVC Model include:\n",
    "- **Training Accuracy:** 91.30%\n",
    "- **Test Accuracy:** 65.23%\n",
    "- **Test Precision:** 67.50%\n",
    "\n",
    "These metrics indicate the model's effectiveness in generalizing to unseen data, making it the most suitable model among those tested in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8283a21c-47d4-48b3-b164-7792b2a6869f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
