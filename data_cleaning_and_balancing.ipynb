{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d759ecc3-a0da-47e8-959b-dee32ff69f48",
   "metadata": {},
   "source": [
    "DATA CLEANING AND BALANCING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ca99f94-c62c-4cb0-8e94-a6d9b06e16e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb7aeb9-e7e9-4b53-8260-ba79c3e0c093",
   "metadata": {},
   "source": [
    "Step 1: Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05017744-9424-4fd7-8e25-0e6d111325e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                            comment       author  \\\n",
      "0      0                                         NC and NH.    Trumpbart   \n",
      "1      0  You do know west teams play against west teams...    Shbshb906   \n",
      "2      0  They were underdogs earlier today, but since G...     Creepeth   \n",
      "3      0  This meme isn't funny none of the \"new york ni...    icebrotha   \n",
      "4      0                    I could use one of those tools.    cush2push   \n",
      "5      0  I don't pay attention to her, but as long as s...  only7inches   \n",
      "6      0      Trick or treating in general is just weird...  only7inches   \n",
      "7      0                    Blade Mastery+Masamune or GTFO!    P0k3rm4s7   \n",
      "8      0  You don't have to, you have a good build, buy ...   SoupToPots   \n",
      "9      0                  I would love to see him at lolla.     chihawks   \n",
      "\n",
      "            subreddit  score  ups  downs     date       created_utc  \\\n",
      "0            politics      2   -1     -1  2016-10  10/16/2016 23:55   \n",
      "1                 nba     -4   -1     -1  2016-11    11/1/2016 0:24   \n",
      "2                 nfl      3    3      0  2016-09   9/22/2016 21:45   \n",
      "3  BlackPeopleTwitter     -8   -1     -1  2016-10  10/18/2016 21:03   \n",
      "4  MaddenUltimateTeam      6   -1     -1  2016-12  12/30/2016 17:00   \n",
      "5           AskReddit      0    0      0  2016-09    9/2/2016 10:35   \n",
      "6           AskReddit      1   -1     -1  2016-10  10/23/2016 21:43   \n",
      "7       FFBraveExvius      2   -1     -1  2016-10  10/13/2016 21:13   \n",
      "8        pcmasterrace      1   -1     -1  2016-10  10/27/2016 19:11   \n",
      "9        Lollapalooza      2   -1     -1  2016-11  11/21/2016 23:39   \n",
      "\n",
      "                                      parent_comment  \n",
      "0  Yeah, I get that argument. At this point, I'd ...  \n",
      "1  The blazers and Mavericks (The wests 5 and 6 s...  \n",
      "2                            They're favored to win.  \n",
      "3                         deadass don't kill my buzz  \n",
      "4  Yep can confirm I saw the tool they use for th...  \n",
      "5                   do you find ariana grande sexy ?  \n",
      "6  What's your weird or unsettling Trick or Treat...  \n",
      "7  Probably Sephiroth. I refuse to taint his grea...  \n",
      "8  What to upgrade? I have $500 to spend (mainly ...  \n",
      "9  Probably count Kanye out Since the rest of his...  \n"
     ]
    }
   ],
   "source": [
    "file_path = 'uncleaned.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the top 10 rows of the uncleaned dataset\n",
    "uncleaned_data = pd.read_csv(file_path)\n",
    "print(uncleaned_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b1167a-b6fa-436e-87af-4b7c6e83431c",
   "metadata": {},
   "source": [
    "Step 2: Remove duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9960943f-edc9-48f8-a0a7-dba272358d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e99dbd-c50e-423f-9304-68a03ade3078",
   "metadata": {},
   "source": [
    "Step 3: Retain only 'label' and 'comment' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0e8c66f-3713-4e09-9424-623524621198",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['label', 'comment']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d28034-a753-42d0-aee8-c5ad11f67468",
   "metadata": {},
   "source": [
    "Step 4: Remove rows with missing or empty 'label' or 'comment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf2dda70-3b27-4af0-b710-7dc3eac3d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['label', 'comment'])\n",
    "data = data[data['comment'].str.strip() != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786050e-078a-4d3f-a8b5-975dbb5f5010",
   "metadata": {},
   "source": [
    "Step 5: Ensure 'label' column contains only 0s and 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f076ee5-71ed-4feb-a95d-af2e361ab893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[(data['label'] == 0) | (data['label'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5864c5-d061-4378-8d39-9a469d3eb12f",
   "metadata": {},
   "source": [
    "Step 6: Balance the number of 0s and 1s in the 'label' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e8b7100-0bd1-4672-850f-aeae4d0d5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of 0s and 1s\n",
    "count_0 = data['label'].value_counts()[0]\n",
    "count_1 = data['label'].value_counts()[1]\n",
    "# Determine the smaller count to balance the dataset\n",
    "min_count = min(count_0, count_1)\n",
    "# Randomly sample min_count number of 0s and 1s\n",
    "data_0 = data[data['label'] == 0].sample(min_count, random_state=1)\n",
    "data_1 = data[data['label'] == 1].sample(min_count, random_state=1)\n",
    "# Concatenate the balanced data\n",
    "balanced_data = pd.concat([data_0, data_1])\n",
    "# Shuffle the balanced data\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558defb-63fd-4293-815e-f683971dc3a7",
   "metadata": {},
   "source": [
    "Step 7: Save the cleaned and balanced dataset to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb920ec1-69e3-4d47-a4b1-b4d13531a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_file_path = 'cleaned_balanced_dataset.csv'\n",
    "balanced_data.to_csv(cleaned_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9f1ec-99b4-4626-b9c9-35fc967b99dd",
   "metadata": {},
   "source": [
    "Display:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43fda0c1-bb50-467c-8de3-42f864a3b561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0s and 1s in the 'label' column:\n",
      "label\n",
      "0    65015\n",
      "1    65015\n",
      "Name: count, dtype: int64\n",
      "Cleaned and balanced dataset saved to cleaned_balanced_dataset.csv\n",
      "   label                                            comment\n",
      "0      0                               All time or current?\n",
      "1      0  I'm also hearing the white noice, i'm not sure...\n",
      "2      1                          You need 8 cameras though\n",
      "3      0                           Trump as Frey confirmed.\n",
      "4      1  I didn't know that Flevoland was bigger in 186...\n",
      "5      1  The thing you should put at the top of your tr...\n",
      "6      1  The only thing Ohio has going for it is that i...\n",
      "7      0                                  Debo, warlock 389\n",
      "8      1       They probably just don't want to get shot...\n",
      "9      0                                      You saw that?\n"
     ]
    }
   ],
   "source": [
    "# Display the count of 0s and 1s in the 'label' column\n",
    "label_counts = balanced_data['label'].value_counts()\n",
    "print(\"Count of 0s and 1s in the 'label' column:\")\n",
    "print(label_counts)\n",
    "\n",
    "print(f\"Cleaned and balanced dataset saved to {cleaned_file_path}\")\n",
    "\n",
    "# Display the top 10 rows of the cleaned dataset\n",
    "cleaned_data = pd.read_csv(cleaned_file_path)\n",
    "print(cleaned_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1988965a-dac7-4f94-9b5b-ae0e6d5d12f4",
   "metadata": {},
   "source": [
    "SPLITING THE CLEANED DATASET TO 80% TRAIN AND 20% TEST DATASETS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cf2fcfe0-c60a-42c7-9910-8fb5cb8742d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into 0s and 1s\n",
    "data_0 = balanced_data[balanced_data['label'] == 0]\n",
    "data_1 = balanced_data[balanced_data['label'] == 1]\n",
    "\n",
    "# Split each into 80% train and 20% test\n",
    "train_0, test_0 = train_test_split(data_0, test_size=0.2, random_state=1)\n",
    "train_1, test_1 = train_test_split(data_1, test_size=0.2, random_state=1)\n",
    "\n",
    "# Combine the training and testing sets\n",
    "train_data = pd.concat([train_0, train_1])\n",
    "test_data = pd.concat([test_0, test_1])\n",
    "\n",
    "# Shuffle the combined training and testing datasets\n",
    "train_data = train_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "\n",
    "# Save the training and testing datasets to new CSV files\n",
    "train_file_path = 'train_dataset.csv'\n",
    "test_file_path = 'test_dataset.csv'\n",
    "\n",
    "train_data.to_csv(train_file_path, index=False)\n",
    "test_data.to_csv(test_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "176a95ed-40e5-4c08-bcb8-70a8e7d08c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of 0s and 1s in the 'label' column of the training dataset:\n",
      "label\n",
      "1    52012\n",
      "0    52012\n",
      "Name: count, dtype: int64\n",
      "Count of 0s and 1s in the 'label' column of the testing dataset:\n",
      "label\n",
      "1    13003\n",
      "0    13003\n",
      "Name: count, dtype: int64\n",
      "Training dataset saved to train_dataset.csv\n",
      "Testing dataset saved to test_dataset.csv\n",
      "Display the top 10 rows of the cleaned TRAIN dataset:\n",
      "   label                                            comment\n",
      "0      1  Everyone knows point guards average less rebou...\n",
      "1      1            Was this meant for r/TheModdingOfIsaac?\n",
      "2      1  I'd say probably overall would be Derm: the lo...\n",
      "3      1                 Bullshit its got a kvlt album art!\n",
      "4      1                                  You forgot to add\n",
      "5      1                  Well, he still has about a month.\n",
      "6      1  I'm sure the Donald will have something to say...\n",
      "7      0  If your values lead you to helping hand this c...\n",
      "8      0  I'm really confused, isn't carnival celebrated...\n",
      "9      1    Like all the delicious Great Value brand foods!\n",
      "Display the top 10 rows of the cleaned TEST dataset\n",
      "   label                                            comment\n",
      "0      1  How am I supposed to correct you if I don't re...\n",
      "1      0    FUCK SAKE MAN don't say that... I'm jobless NOW\n",
      "2      1                  So how much did Nintendo pay you?\n",
      "3      0  But a dining room table has a purpose, don't p...\n",
      "4      0  I had troubled drifting the AWD around thanks ...\n",
      "5      1             But no, Bernie would have been better.\n",
      "6      0      I think you're just out of defensible points.\n",
      "7      0                                              okay.\n",
      "8      1  And while we are at it, why don't we also star...\n",
      "9      0       next its going to be \"gg broken game i quit\"\n"
     ]
    }
   ],
   "source": [
    "# Display the count of 0s and 1s in the training and testing datasets\n",
    "train_label_counts = train_data['label'].value_counts()\n",
    "test_label_counts = test_data['label'].value_counts()\n",
    "\n",
    "print(\"Count of 0s and 1s in the 'label' column of the training dataset:\")\n",
    "print(train_label_counts)\n",
    "\n",
    "print(\"Count of 0s and 1s in the 'label' column of the testing dataset:\")\n",
    "print(test_label_counts)\n",
    "\n",
    "print(f\"Training dataset saved to {train_file_path}\")\n",
    "print(f\"Testing dataset saved to {test_file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Display the top 10 rows of the cleaned train dataset\n",
    "print(\"Display the top 10 rows of the cleaned TRAIN dataset:\")\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "print(train_data.head(10))\n",
    "\n",
    "# Display the top 10 rows of the cleaned test dataset\n",
    "print(\"Display the top 10 rows of the cleaned TEST dataset\")\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "print(test_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f22da-61ea-43dc-8297-b8fc85fe5db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c7b5d-48a2-4aca-9be6-a80fd09cc5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47f934-fa17-4687-a381-39694b318809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
